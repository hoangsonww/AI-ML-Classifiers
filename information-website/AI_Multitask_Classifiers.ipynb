{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "e6141e55235e57c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI Multitask Classifiers: From Objects to Emotions\n",
    "\n",
    "## Introduction\n",
    "This project showcases various AI classifiers including object detection, face detection, character recognition, and mood classification, using OpenCV, TensorFlow, PyTorch, and Tesseract.\n",
    "\n",
    "## Setup\n",
    "To start, install the required libraries:\n",
    "\n",
    "```python\n",
    "!pip install numpy opencv-python-headless tensorflow torch pytesseract matplotlib\n",
    "```\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "```\n",
    "\n",
    "## Load Models\n",
    "\n",
    "### Object Detection (YOLOv3)\n",
    "\n",
    "```python\n",
    "yolo_model = cv2.dnn.readNetFromDarknet('path/to/yolov3.cfg', 'path/to/yolov3.weights')\n",
    "yolo_model.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo_model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "with open(\"path/to/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "```\n",
    "\n",
    "### Face Detection (TensorFlow)\n",
    "\n",
    "```python\n",
    "tf_model = tf.keras.models.load_model('path/to/face_detection_model.h5')\n",
    "```\n",
    "\n",
    "### Mood Classification (PyTorch)\n",
    "\n",
    "```python\n",
    "torch_model = torch.load('path/to/mood_classification_model.pth')\n",
    "torch_model.eval()\n",
    "```\n",
    "\n",
    "## Running Classifications\n",
    "\n",
    "### Object Detection with YOLO\n",
    "\n",
    "```python\n",
    "def detect_objects_yolo(image_path, model, classes):\n",
    "    image = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    model.setInput(blob)\n",
    "    \n",
    "    layer_names = model.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in model.getUnconnectedOutLayers()]\n",
    "    \n",
    "    outputs = model.forward(output_layers)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    \n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                centerX, centerY, w, h = box.astype(\"int\")\n",
    "                x = int(centerX - (w / 2))\n",
    "                y = int(centerY - (h / 2))\n",
    "                boxes.append([x, y, int(w), int(h)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "                \n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    results = [(boxes[i], confidences[i], classes[class_ids[i]]) for i in indices.flatten()]\n",
    "    return results\n",
    "\n",
    "yolo_results = detect_objects_yolo('path/to/object/image.jpg', yolo_model, classes)\n",
    "print(\"YOLO Object Detection Results:\", yolo_results)\n",
    "```\n",
    "\n",
    "### Face Detection with TensorFlow\n",
    "\n",
    "```python\n",
    "def detect_faces_tf(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    image_array = np.array(image) / 255.0\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    predictions = model.predict(image_array)\n",
    "    return predictions\n",
    "\n",
    "tf_results = detect_faces_tf('path/to/face/image.jpg', tf_model)\n",
    "print(\"TensorFlow Face Detection Results:\", tf_results)\n",
    "```\n",
    "\n",
    "### Mood Classification with PyTorch\n",
    "\n",
    "```python\n",
    "def classify_mood_torch(image_path, model):\n",
    "    image = Image.open(image_path)\n",
    "    transform = torch.nn.Sequential(\n",
    "        torch.transforms.Resize((224, 224)),\n",
    "        torch.transforms.ToTensor(),\n",
    "        torch.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    )\n",
    "    \n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    mood = 'Happy' if predicted.item() == 1 else 'Sad'\n",
    "    return mood\n",
    "\n",
    "torch_results = classify_mood_torch('path/to/mood/image.jpg', torch_model)\n",
    "print(\"PyTorch Mood Classification Results:\", torch_results)\n",
    "```\n",
    "\n",
    "## Results and Analysis\n",
    "\n",
    "### Displaying YOLO Object Detection Results\n",
    "\n",
    "```python\n",
    "def display_yolo_results(image_path, results):\n",
    "    image = cv2.imread(image_path)\n",
    "    for (box, confidence, label) in results:\n",
    "        x, y, w, h = box\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"{label}: {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "display_yolo_results('path/to/object/image.jpg', yolo_results)\n",
    "```\n",
    "\n",
    "### Displaying TensorFlow Face Detection Results\n",
    "\n",
    "```python\n",
    "print(\"TensorFlow Face Detection Results:\", tf_results)\n",
    "```\n",
    "\n",
    "### Displaying PyTorch Mood Classification Results\n",
    "\n",
    "```python\n",
    "print(\"Mood Classification Result:\", torch_results)\n",
    "```\n",
    "\n",
    "## Additional Classifiers\n",
    "\n",
    "### Character Recognition (OCR)\n",
    "\n",
    "```python\n",
    "def recognize_text(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "ocr_result = recognize_text('path/to/text/image.jpg')\n",
    "print(\"OCR Result:\", ocr_result)\n",
    "```\n",
    "\n",
    "### Speech Recognition\n",
    "\n",
    "```python\n",
    "import speech_recognition as sr\n",
    "\n",
    "def recognize_speech(audio_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_path) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    return text\n",
    "\n",
    "speech_result = recognize_speech('path/to/audio/file.wav')\n",
    "print(\"Speech Recognition Result:\", speech_result)\n",
    "```\n",
    "\n",
    "### Sentiment Analysis\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "sentiment_result = sentiment_analyzer(\"This is a great project!\")\n",
    "print(\"Sentiment Analysis Result:\", sentiment_result)\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "This project demonstrates using multiple classifiers for tasks such as object detection, face detection, mood classification, OCR, and sentiment analysis."
   ],
   "id": "7232f94c6e1c1cc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
